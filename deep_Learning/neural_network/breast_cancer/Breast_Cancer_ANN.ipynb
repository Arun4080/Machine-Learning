{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection using neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['code_id','Clump_Thickness','Cell_size','Cell_Shape','Marginal_Adhesion','singleEpithelialCellSize','bareNuclei','blandChromatin','normalNucleoli','Mitoses','Class']\n",
    "dataset=pd.read_csv('data/breast-cancer.csv',names=names)\n",
    "\n",
    "array = dataset.values\n",
    "x = array[ : , 1:10]\n",
    "y = array[ : , 10]\n",
    "x=x/10\n",
    "y=pd.get_dummies([str(i) for i in y]).values\n",
    "validation_size = 0.10\n",
    "\n",
    "X_train , X_Validation , Y_train , Y_Validation = train_test_split(x , y , test_size=validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "  def __init__(self):\n",
    "  #parameters\n",
    "    self.inputSize = 9 #no of input in neural network\n",
    "    self.hl1Size = 20 #no of nodes in hidden layer 1\n",
    "    self.hl2Size = 20 #no of nodes in hidden layer 2\n",
    "    self.outputSize = 2 #no of layer in output layer\n",
    "\n",
    "  #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hl1Size) \n",
    "    self.W2 = np.random.randn(self.hl1Size,self.hl2Size) \n",
    "    self.W3 = np.random.randn(self.hl2Size, self.outputSize) \n",
    "    self.b1=np.random.randn(self.hl1Size)\n",
    "    self.b2=np.random.randn(self.hl2Size)\n",
    "    self.b3=np.random.randn(self.outputSize)\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1)+self.b1 # dot product of X (input) and first set of weights and adding bias\n",
    "    self.hl1 = self.sigmoid(self.z) # activation function\n",
    "    \n",
    "    self.z2 = np.dot(self.hl1, self.W2)+self.b2 # dot product of hidden layer1 and second set of weights and adding bias\n",
    "    self.hl2 = self.sigmoid(self.z2) # activation function\n",
    "    \n",
    "    self.z3 = np.dot(self.hl2, self.W3)+self.b3 # dot product of hidden layer2 and third set of weights and adding bias\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    \n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "  def sigmoidPrime(self, s):\n",
    "    #derivative of sigmoid\n",
    "    return s * (1 - s)\n",
    "\n",
    "  def backward(self, X, y, o):\n",
    "    # backward propagate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "\n",
    "    self.z3_error = self.o_delta.dot(self.W3.T)\n",
    "    self.z3_delta = self.z3_error*self.sigmoidPrime(self.hl2) \n",
    "    \n",
    "    self.z2_error = self.z3_delta.dot(self.W2.T) \n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.hl1) \n",
    "\n",
    "    self.W1 += X.reshape(self.inputSize,1).dot(self.z2_delta.reshape(1,self.hl1Size)) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.hl1.T.dot(self.z3_delta) # adjusting second set (hidden --> output) weights\n",
    "    self.W3 += self.hl2.reshape(self.hl2Size,1).dot(self.o_delta.reshape(1,self.outputSize)) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "  def train(self, X, y, n=1,batch=50):\n",
    "    min,hw1,hw2,hw3,hb1,hb2,hb3=1,0,0,0,0,0,0\n",
    "    print(\"Before Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "    for j in range(n):\n",
    "        for k in range(0,len(X),batch):\n",
    "            avg_loss=[]\n",
    "            for i in range(k,k+batch):\n",
    "                o = self.forward(X[i])\n",
    "                self.backward(X[i], y[i], o)\n",
    "                l=np.mean(np.square(y - self.forward(X)))\n",
    "                avg_loss.append(l)\n",
    "                if min>l:\n",
    "                    min=l\n",
    "                    hw1,hb1=self.W1,self.b1\n",
    "                    hw2,hb2=self.W2,self.b2\n",
    "                    hw3,hb3=self.W3,self.b3\n",
    "            print(\"avg loss of this batch is \" + str(np.mean(avg_loss)))\n",
    "              \n",
    "    print(\"min loss: \"+str(min))\n",
    "    self.W1,self.b1=hw1,hb1\n",
    "    self.W2,self.b2=hw2,hb2\n",
    "    self.W3,self.b3=hw3,hb3\n",
    "    print(\"After Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "   \n",
    "  def predict(self,X):\n",
    "    return self.forward(X).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training loss: 0.31118092471937053\n",
      "avg loss of this batch is 0.15377437535946012\n",
      "avg loss of this batch is 0.0641875364382524\n",
      "avg loss of this batch is 0.041346425468629246\n",
      "avg loss of this batch is 0.0351544908349524\n",
      "avg loss of this batch is 0.04098678592236211\n",
      "avg loss of this batch is 0.033619637747617344\n",
      "avg loss of this batch is 0.030019746323750814\n",
      "avg loss of this batch is 0.03595621266264938\n",
      "avg loss of this batch is 0.031067224914795487\n",
      "avg loss of this batch is 0.028224364548566656\n",
      "avg loss of this batch is 0.03330972832646668\n",
      "avg loss of this batch is 0.029787332781018704\n",
      "avg loss of this batch is 0.02712599383497146\n",
      "avg loss of this batch is 0.03216454011687791\n",
      "avg loss of this batch is 0.027849113297306573\n",
      "min loss: 0.022923777370678692\n",
      "After Training loss: 0.023280306171641826\n"
     ]
    }
   ],
   "source": [
    "NN=Neural_Network()\n",
    "NN.train(X_train,Y_train,n=5,batch=210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "prediction=NN.predict(X_Validation)\n",
    "print(\"accuracy is \"+str(accuracy_score(Y_Validation, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
