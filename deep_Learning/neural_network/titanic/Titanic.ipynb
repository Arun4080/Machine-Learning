{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Servivers classification using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\arun\\installed\\python3\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "d:\\arun\\installed\\python3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "d:\\arun\\installed\\python3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "d:\\arun\\installed\\python3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "d:\\arun\\installed\\python3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/train.csv\")\n",
    "test_X=pd.read_csv(\"data/test.csv\")\n",
    "test_Y=pd.read_csv(\"data/gender_submission.csv\")\n",
    "\n",
    "def extract(data):\n",
    "    x=data[['Pclass','Sex','Age','SibSp','Parch','Embarked']]\n",
    "    x['Age'].fillna(x['Age'].mean(),inplace=True)\n",
    "    x['Embarked'].fillna('S')\n",
    "    x['Pclass']=x['Pclass']/3\n",
    "    x['Age']=x['Age']/80.0\n",
    "    x['SibSp']=x['SibSp']/8\n",
    "    x['Parch']=x['Parch']/6\n",
    "    #x['Fare']=x['Fare']/600\n",
    "    return pd.get_dummies(x).values\n",
    "\n",
    "train_x=extract(data)\n",
    "test_x=extract(test_X)\n",
    "\n",
    "train_y=[str(i) for i in data.Survived]\n",
    "test_y=[str(i) for i in test_Y.Survived]\n",
    "train_y,test_y=pd.get_dummies(train_y).values,pd.get_dummies(test_y).values\n",
    "del(data,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "  def __init__(self):\n",
    "  #parameters\n",
    "    self.inputSize = 9 #no of input in neural network\n",
    "    self.hl1Size = 30 #no of nodes in hidden layer 1\n",
    "    self.hl2Size = 30 #no of nodes in hidden layer 2\n",
    "    self.outputSize = 2 #no of layer in output layer\n",
    "\n",
    "  #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hl1Size) \n",
    "    self.W2 = np.random.randn(self.hl1Size,self.hl2Size) \n",
    "    self.W3 = np.random.randn(self.hl2Size, self.outputSize) \n",
    "    self.b1=np.random.randn(self.hl1Size)\n",
    "    self.b2=np.random.randn(self.hl2Size)\n",
    "    self.b3=np.random.randn(self.outputSize)\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1)+self.b1 # dot product of X (input) and first set of weights and adding bias\n",
    "    self.hl1 = self.sigmoid(self.z) # activation function\n",
    "    \n",
    "    self.z2 = np.dot(self.hl1, self.W2)+self.b2 # dot product of hidden layer1 and second set of weights and adding bias\n",
    "    self.hl2 = self.sigmoid(self.z2) # activation function\n",
    "    \n",
    "    self.z3 = np.dot(self.hl2, self.W3)+self.b3 # dot product of hidden layer2 and third set of weights and adding bias\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    \n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "  def sigmoidPrime(self, s):\n",
    "    #derivative of sigmoid\n",
    "    return s * (1 - s)\n",
    "\n",
    "  def backward(self, X, y, o):\n",
    "    # backward propagate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "\n",
    "    self.z3_error = self.o_delta.dot(self.W3.T)\n",
    "    self.z3_delta = self.z3_error*self.sigmoidPrime(self.hl2) \n",
    "    \n",
    "    self.z2_error = self.z3_delta.dot(self.W2.T) \n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.hl1) \n",
    "\n",
    "    self.W1 += X.reshape(self.inputSize,1).dot(self.z2_delta.reshape(1,self.hl1Size)) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.hl1.T.dot(self.z3_delta) # adjusting second set (hidden --> output) weights\n",
    "    self.W3 += self.hl2.reshape(self.hl2Size,1).dot(self.o_delta.reshape(1,self.outputSize)) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "  def train(self, X, y, n=1,batch=50):\n",
    "    min,hw1,hw2,hw3,hb1,hb2,hb3=1,0,0,0,0,0,0\n",
    "    print(\"Before Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "    for j in range(n):\n",
    "        for k in range(0,len(X),batch):\n",
    "            avg_loss=[]\n",
    "            for i in range(k,k+batch):\n",
    "                o = self.forward(X[i])\n",
    "                self.backward(X[i], y[i], o)\n",
    "                l=np.mean(np.square(y - self.forward(X)))\n",
    "                avg_loss.append(l)\n",
    "                if min>l:\n",
    "                    min=l\n",
    "                    hw1,hb1=self.W1,self.b1\n",
    "                    hw2,hb2=self.W2,self.b2\n",
    "                    hw3,hb3=self.W3,self.b3\n",
    "            print(\"avg loss of this batch is \" + str(np.mean(avg_loss)))\n",
    "              \n",
    "    print(\"min loss: \"+str(min))\n",
    "    self.W1,self.b1=hw1,hb1\n",
    "    self.W2,self.b2=hw2,hb2\n",
    "    self.W3,self.b3=hw3,hb3\n",
    "    print(\"After Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "   \n",
    "  def predict(self,X):\n",
    "    return self.forward(X).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training loss: 0.37393089682943526\n",
      "avg loss of this batch is 0.20280455320609042\n",
      "avg loss of this batch is 0.1737401957890361\n",
      "avg loss of this batch is 0.1583609532643388\n",
      "avg loss of this batch is 0.1555128365249644\n",
      "avg loss of this batch is 0.1583082662738791\n",
      "avg loss of this batch is 0.15378307340666503\n",
      "avg loss of this batch is 0.15212796919872335\n",
      "avg loss of this batch is 0.15260709190921953\n",
      "avg loss of this batch is 0.1500476313629593\n",
      "avg loss of this batch is 0.15105759269306965\n",
      "avg loss of this batch is 0.1489367900236295\n",
      "avg loss of this batch is 0.1471797377261384\n",
      "avg loss of this batch is 0.1502796473642819\n",
      "avg loss of this batch is 0.14629148895037578\n",
      "avg loss of this batch is 0.14460950818671775\n",
      "avg loss of this batch is 0.1485485413820073\n",
      "avg loss of this batch is 0.1441913114943492\n",
      "avg loss of this batch is 0.14227858436258378\n",
      "avg loss of this batch is 0.1472985558957148\n",
      "avg loss of this batch is 0.14180969079787895\n",
      "avg loss of this batch is 0.14064550952896487\n",
      "avg loss of this batch is 0.1462242396019633\n",
      "avg loss of this batch is 0.14032527805856634\n",
      "avg loss of this batch is 0.1394260750719489\n",
      "avg loss of this batch is 0.1453275164703038\n",
      "avg loss of this batch is 0.13944920548550124\n",
      "avg loss of this batch is 0.13846599387877087\n",
      "avg loss of this batch is 0.14511571859106484\n",
      "avg loss of this batch is 0.13872441890208936\n",
      "avg loss of this batch is 0.13769733496152445\n",
      "min loss: 0.1339458318908414\n",
      "After Training loss: 0.14212380526414986\n"
     ]
    }
   ],
   "source": [
    "NN=Neural_Network()\n",
    "NN.train(train_x,train_y,n=10,batch=297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=NN.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301435406698564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=0\n",
    "t=len(prediction)\n",
    "for i in range(t):\n",
    "    try:\n",
    "        if accuracy_score(test_y[i].astype(\"float\").round(), prediction[i].round())==1.0:\n",
    "            n+=1\n",
    "    except:pass\n",
    "output=n/t\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
