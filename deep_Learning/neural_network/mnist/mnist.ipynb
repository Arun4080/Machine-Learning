{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data and seprating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\")\n",
    "#test_X=pd.read_csv(\"data/test.csv\")\n",
    "#test_Y=pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f5ebf76084ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#del(train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train_X=train.drop([\"label\"],axis=1).values\n",
    "train_Y=pd.get_dummies([str(i) for i in train.label]).values\n",
    "del(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "  def __init__(self):\n",
    "  #parameters\n",
    "    self.inputSize = 784\n",
    "    self.hl1Size = 100\n",
    "    self.hl2Size = 100\n",
    "    self.outputSize = 10\n",
    "\n",
    "  #weights\n",
    "    self.W1 = np.random.randn(self.inputSize, self.hl1Size) \n",
    "    self.W2 = np.random.randn(self.hl1Size,self.hl2Size) \n",
    "    self.W3 = np.random.randn(self.hl2Size, self.outputSize)\n",
    "    self.b1=np.random.randn(self.hl1Size)\n",
    "    self.b2=np.random.randn(self.hl2Size)\n",
    "    self.b3=np.random.randn(self.outputSize)\n",
    "\n",
    "  def forward(self, X):\n",
    "    #forward propagation through our network\n",
    "    self.z = np.dot(X, self.W1)+self.b1 # dot product of X (input) and first set of weights and adding bias\n",
    "    self.hl1 = self.sigmoid(self.z) # activation function\n",
    "    \n",
    "    self.z2 = np.dot(self.hl1, self.W2)+self.b2 # dot product of hidden layer1 and second set of weights and adding bias\n",
    "    self.hl2 = self.sigmoid(self.z2) # activation function\n",
    "    \n",
    "    self.z3 = np.dot(self.hl2, self.W3)+self.b3 # dot product of hidden layer2 and third set of weights and adding bias\n",
    "    o = self.sigmoid(self.z3) # final activation function\n",
    "    \n",
    "    return o\n",
    "\n",
    "  def sigmoid(self, s):\n",
    "    # activation function\n",
    "    return 1/(1+np.exp(-s))\n",
    "\n",
    "  def sigmoidPrime(self, s):\n",
    "    #derivative of sigmoid\n",
    "    return s * (1 - s)\n",
    "\n",
    "  def backward(self, X, y, o):\n",
    "    # backward propagate through the network\n",
    "    self.o_error = y - o # error in output\n",
    "    self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "\n",
    "    self.z3_error = self.o_delta.dot(self.W3.T)\n",
    "    self.z3_delta = self.z3_error*self.sigmoidPrime(self.hl2) \n",
    "    \n",
    "    self.z2_error = self.z3_delta.dot(self.W2.T) \n",
    "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.hl1) \n",
    "\n",
    "    self.W1 += X.reshape(self.inputSize,1).dot(self.z2_delta.reshape(1,self.hl1Size)) # adjusting first set (input --> hidden) weights\n",
    "    self.W2 += self.hl1.T.dot(self.z3_delta) # adjusting second set (hidden --> output) weights\n",
    "    self.W3 += self.hl2.reshape(self.hl2Size,1).dot(self.o_delta.reshape(1,self.outputSize)) # adjusting second set (hidden --> output) weights\n",
    "\n",
    "  def train(self, X, y, n=1,batch=50):\n",
    "    min,hw1,hw2,hw3,hb1,hb2,hb3=1,0,0,0,0,0,0\n",
    "    print(\"Before Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "    for j in range(n):\n",
    "        for k in range(0,len(X),batch):\n",
    "            avg_loss=[]\n",
    "            for i in range(k,k+batch):\n",
    "                o = self.forward(X[i])\n",
    "                self.backward(X[i], y[i], o)\n",
    "                l=np.mean(np.square(y - self.forward(X)))\n",
    "                avg_loss.append(l)\n",
    "                if min>l:\n",
    "                    min=l\n",
    "                    hw1,hb1=self.W1,self.b1\n",
    "                    hw2,hb2=self.W2,self.b2\n",
    "                    hw3,hb3=self.W3,self.b3\n",
    "            print(\"avg loss of this batch is \" + str(np.mean(avg_loss)))\n",
    "              \n",
    "    print(\"min loss: \"+str(min))\n",
    "    self.W1,self.b1=hw1,hb1\n",
    "    self.W2,self.b2=hw2,hb2\n",
    "    self.W3,self.b3=hw3,hb3\n",
    "    print(\"After Training loss: \"+str(np.mean(np.square(y - self.forward(X)))))\n",
    "    \n",
    "\n",
    "  def predict(self,X):\n",
    "    return self.forward(X).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\arun\\installed\\python3\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training loss: 0.4312404259285261\n",
      "avg loss of this batch is 0.12003755927595233\n",
      "avg loss of this batch is 0.09987232960944573\n"
     ]
    }
   ],
   "source": [
    "NN=Neural_Network()\n",
    "NN.train(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
